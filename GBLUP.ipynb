{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G matrix:\n",
      "[[ 2.38235294 -0.52941176 -1.85294118]\n",
      " [-0.52941176  1.05882353 -0.52941176]\n",
      " [-1.85294118 -0.52941176  2.38235294]]\n",
      "\n",
      "G matrix with imputed missing values:\n",
      "[[ 1.97419355 -0.05806452 -1.91612903]\n",
      " [-0.05806452  0.37741935 -0.31935484]\n",
      " [-1.91612903 -0.31935484  2.23548387]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from typing import Optional, Union, Tuple\n",
    "\n",
    "def calculate_G_matrix(M: np.ndarray, \n",
    "                      method: str = \"vanraden1\", \n",
    "                      missing_value: Optional[Union[int, float]] = None,\n",
    "                      min_maf: float = 0.01) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculate the genomic relationship matrix G using VanRaden (2008) methods.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    M : numpy.ndarray\n",
    "        Genotype matrix with dimensions (n, m), \n",
    "        where n is the number of individuals, m is the number of markers.\n",
    "        M_ij is the genotype of individual i at marker j (0, 1, 2).\n",
    "    method : str, optional\n",
    "        Method to calculate G matrix. Options:\n",
    "        - \"vanraden1\": G = ZZ'/total_variance (default)\n",
    "        - \"vanraden2\": G = (M-P)(M-P)'/sum(2pq)\n",
    "    missing_value : int or float, optional\n",
    "        Value used to represent missing genotypes. If provided, will be replaced with mean.\n",
    "    min_maf : float, optional\n",
    "        Minimum minor allele frequency threshold. Markers with MAF < min_maf will be excluded.\n",
    "        Default is 0.01 (1%).\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    G : numpy.ndarray\n",
    "        Genomic relationship matrix G with dimensions (n, n).\n",
    "    \n",
    "    References:\n",
    "    -----------\n",
    "    VanRaden, P. M. (2008). Efficient methods to compute genomic predictions.\n",
    "    Journal of Dairy Science, 91(11), 4414-4423.\n",
    "    \"\"\"\n",
    "    # Get the dimensions of matrix M\n",
    "    n, m = M.shape  # n: number of individuals, m: number of markers\n",
    "    \n",
    "    # Handle missing values if specified\n",
    "    M_clean = M.copy()\n",
    "    if missing_value is not None:\n",
    "        mask = M_clean == missing_value\n",
    "        if np.any(mask):\n",
    "            for j in range(m):\n",
    "                col_mask = mask[:, j]\n",
    "                if np.any(col_mask):\n",
    "                    # Replace missing with mean of non-missing values\n",
    "                    non_missing = M_clean[~col_mask, j]\n",
    "                    if len(non_missing) > 0:\n",
    "                        M_clean[col_mask, j] = np.mean(non_missing)\n",
    "    \n",
    "    # Step 1: Calculate allele frequency p_j for each marker\n",
    "    p = np.sum(M_clean, axis=0) / (2 * n)  # Minor allele frequency\n",
    "    \n",
    "    # Filter markers by MAF\n",
    "    valid_markers = np.where((p >= min_maf) & (p <= 1 - min_maf))[0]\n",
    "    if len(valid_markers) < m:\n",
    "        print(f\"Filtered out {m - len(valid_markers)} markers with MAF < {min_maf}\")\n",
    "        if len(valid_markers) == 0:\n",
    "            raise ValueError(f\"No markers left after MAF filtering. Consider lowering min_maf.\")\n",
    "        M_clean = M_clean[:, valid_markers]\n",
    "        p = p[valid_markers]\n",
    "        m = len(valid_markers)\n",
    "    \n",
    "    # Step 2: Create matrix P with P_ij = 2 * p_j\n",
    "    P = np.tile(2 * p, (n, 1))  # Create n x m matrix from vector 2*p\n",
    "    \n",
    "    # Step 3: Calculate matrix Z = M - P\n",
    "    Z = M_clean - P\n",
    "    \n",
    "    # Step 4: Calculate denominator (total variance)\n",
    "    total_variance = np.sum(2 * p * (1 - p))\n",
    "    \n",
    "    # Method implementation\n",
    "    if method.lower() == \"vanraden1\":\n",
    "        \n",
    "        # Step 5: Normalize Z\n",
    "        std_dev = np.sqrt(2 * p * (1 - p))\n",
    "        # Avoid division by zero (for very low variance markers)\n",
    "        std_dev[std_dev < 1e-10] = 1e-10\n",
    "        W = Z / std_dev\n",
    "        \n",
    "        # Calculate G matrix\n",
    "        G = np.dot(W, W.T) / total_variance\n",
    "        \n",
    "    elif method.lower() == \"vanraden2\":\n",
    "        # Alternative method directly using Z\n",
    "        G = np.dot(Z, Z.T) / total_variance\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}. Use 'vanraden1' or 'vanraden2'.\")\n",
    "    \n",
    "    return G\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample genotype matrix (3 individuals, 4 markers)\n",
    "    M_sample = np.array([\n",
    "        [0, 1, 2, 1],\n",
    "        [1, 2, 1, 0],\n",
    "        [2, 1, 0, 1]\n",
    "    ])\n",
    "    G = calculate_G_matrix(M_sample)\n",
    "    print(\"G matrix:\")\n",
    "    print(G)\n",
    "    \n",
    "    # With missing values (coded as -9)\n",
    "    M_missing = np.array([\n",
    "        [0, 1, 2, -9],\n",
    "        [1, -9, 1, 0],\n",
    "        [2, 1, -9, 1]\n",
    "    ])\n",
    "    G_imputed = calculate_G_matrix(M_missing, missing_value=-9, method=\"vanraden1\")\n",
    "    print(\"\\nG matrix with imputed missing values:\")\n",
    "    print(G_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import inv, pinv\n",
    "\n",
    "def estimate_variance_components(y: np.ndarray, X: np.ndarray, Z: np.ndarray, G: np.ndarray, \n",
    "                                 epsilon=1e-2, max_iter=100, regularization=1e-5\n",
    "                                 ) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Estimate the genomic variance (sigma_g^2) and error variance (sigma_e^2) using the REML method with EM algorithm.\n",
    "\n",
    "    Parameters:\n",
    "    - y: numpy array, phenotype vector (n x 1)\n",
    "    - X: numpy array, design matrix for fixed effects (n x p)\n",
    "    - Z: numpy array, design matrix for random effects (n x q)\n",
    "    - G: numpy array, genomic relationship matrix (q x q)\n",
    "    - epsilon: float, convergence threshold\n",
    "    - max_iter: int, maximum number of iterations\n",
    "\n",
    "    Returns:\n",
    "    - sigma_g2: float, estimated genomic variance\n",
    "    - sigma_e2: float, estimated error variance\n",
    "    \"\"\"\n",
    "    # Get dimensions\n",
    "    n, p = X.shape  # n: number of observations, p: number of fixed effects\n",
    "    q = Z.shape[1]  # q: number of random effects\n",
    "    \n",
    "    # Initialize variance components with starting values\n",
    "    var_y = np.var(y)\n",
    "    sigma_g2 = 0.5 * var_y  # Initial guess for genomic variance\n",
    "    sigma_e2 = 0.5 * var_y  # Initial guess for error variance\n",
    "    \n",
    "    # Precompute inverse of G for efficiency\n",
    "    G_inv = inv(G)\n",
    "    \n",
    "    # Iterative process\n",
    "    for iteration in range(max_iter):\n",
    "        print(\"Iteration\", iteration)\n",
    "        print(\"sigma_g2:\", sigma_g2, \"sigma_e2:\", sigma_e2)\n",
    "        # Step 1: Compute the variance matrix V\n",
    "        V = Z @ (G * sigma_g2) @ Z.T + np.eye(n) * sigma_e2\n",
    "        \n",
    "        # Step 2: Compute the inverse of V\n",
    "        try:\n",
    "            V_inv = inv(V)\n",
    "        except np.linalg.LinAlgError:\n",
    "            print(\"Warning: V matrix is near-singular. Adding regularization to proceed.\")\n",
    "            # Add regularization to diagonal elements\n",
    "            V_reg = V + np.eye(n) * regularization\n",
    "            V_inv = inv(V_reg)\n",
    "        \n",
    "        # Step 3: Compute the projection matrix P\n",
    "        XVX = X.T @ V_inv @ X\n",
    "        try:\n",
    "            XVX_inv = inv(XVX)\n",
    "        except np.linalg.LinAlgError:\n",
    "            print(\"Warning: Singular matrix XVX. Using pseudo-inverse instead.\")\n",
    "            # Add regularization to diagonal elements\n",
    "            XVX_reg = XVX + np.eye(p) * regularization\n",
    "            XVX_inv = inv(XVX_reg)\n",
    "\n",
    "        P = V_inv - V_inv @ X @ XVX_inv @ X.T @ V_inv\n",
    "        \n",
    "        # Step 4: Update sigma_e^2 using y' P y\n",
    "        yPy = y.T @ P @ y\n",
    "        sigma_e2_new = yPy / (n - p)\n",
    "        \n",
    "        # Step 5: Compute temporary estimate of random effects (g_hat)\n",
    "        g_hat = sigma_g2 * Z.T @ P @ y\n",
    "        \n",
    "        # Step 6: Compute the covariance matrix C_gg\n",
    "        C_gg = sigma_g2 * np.eye(q) - sigma_g2**2 * Z.T @ P @ Z\n",
    "        \n",
    "        # Step 7: Update sigma_g^2 using g_hat and trace term\n",
    "        term1 = g_hat.T @ G_inv @ g_hat\n",
    "        term2 = np.trace(G_inv @ C_gg)\n",
    "        sigma_g2_new = (term1 + term2) / q\n",
    "        \n",
    "        # Step 8: Check convergence\n",
    "        if abs(sigma_g2_new - sigma_g2) < epsilon and abs(sigma_e2_new - sigma_e2) < epsilon:\n",
    "            print(\"EM algorithm converged after\", iteration, \"iterations!\")\n",
    "            break\n",
    "        \n",
    "        # Update variance components for the next iteration\n",
    "        sigma_g2_new = max(sigma_g2_new, 1e-6)\n",
    "        sigma_e2_new = max(sigma_e2_new, 1e-6)\n",
    "        sigma_g2 = sigma_g2_new\n",
    "        sigma_e2 = sigma_e2_new\n",
    "    \n",
    "    return sigma_g2, sigma_e2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pev_and_accuracy(sigma_g: float, \n",
    "                               sigma_e: float, \n",
    "                               C_inv: np.ndarray,\n",
    "                               n: int   # number of individuals\n",
    "                               ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Calculate the Prediction Error Variance (PEV) and accuracy for each individual.\n",
    "\n",
    "    Parameters:\n",
    "    - sigma_g: float, genomic variance (sigma_g)\n",
    "    - sigma_e: float, error variance (sigma_e)\n",
    "    - C_inv: numpy array, inverse of the coefficient matrix C from the mixed model equations\n",
    "\n",
    "    Returns:\n",
    "    - PEV: numpy array, prediction error variance for each individual\n",
    "    - accuracy: numpy array, accuracy for each individual\n",
    "    \"\"\"\n",
    "\n",
    "    # C_inv is the inverse of the coefficient matrix C from the mixed model equations\n",
    "    # Extract the lower right block of C_inv corresponding to G^-1\n",
    "    C_gg = C_inv[-n:, -n:]\n",
    "\n",
    "    # Extract the diagonal elements of C^gg\n",
    "    diag_C_gg = np.diag(C_gg)\n",
    "\n",
    "    # Calculate PEV for each individual\n",
    "    PEV = sigma_g - diag_C_gg * sigma_e\n",
    "\n",
    "    # Calculate accuracy for each individual\n",
    "    accuracy = np.sqrt(1 - PEV / sigma_g)\n",
    "\n",
    "    return PEV, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_gblup(y: np.ndarray,\n",
    "                X: np.ndarray, \n",
    "                Z: np.ndarray, \n",
    "                G: np.ndarray,\n",
    "                sigma_g: float,\n",
    "                sigma_e: float, \n",
    "                reg_factor: float = 1e-5\n",
    "                ) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Solve the GBLUP equation system to find beta and g using numpy.linalg.solve.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : numpy.ndarray\n",
    "        Design matrix for fixed effects (n x p).\n",
    "    Z : numpy.ndarray\n",
    "        Design matrix for random effects (n x q).\n",
    "    G : numpy.ndarray\n",
    "        Genomic relationship matrix (q x q).\n",
    "    lambda_ : float\n",
    "        Lambda ratio = sigma_e^2 / sigma_g^2.\n",
    "    y : numpy.ndarray\n",
    "        Phenotypes vector (n x 1).\n",
    "    reg_factor : float, optional\n",
    "        Regularization factor added to the diagonal for numerical stability.\n",
    "        Default is 1e-6.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    beta : numpy.ndarray\n",
    "        Estimated fixed effects vector (p x 1).\n",
    "    g : numpy.ndarray\n",
    "        Predicted genomic breeding values vector (q x 1).\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    This function implements the GBLUP method to estimate fixed effects and \n",
    "    genomic breeding values by solving a mixed linear model equation system.\n",
    "    The approach combines fixed and random effects to predict genomic breeding \n",
    "    values, crucial in genomic selection studies.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Validate input dimensions\n",
    "    n = X.shape[0]\n",
    "    p = X.shape[1]\n",
    "    q = Z.shape[1]\n",
    "    \n",
    "    if X.shape[0] != Z.shape[0]:\n",
    "        raise ValueError(\"X and Z must have the same number of rows (samples).\")\n",
    "    if G.shape[0] != q:\n",
    "        raise ValueError(\"G must be a square matrix of size q x q.\")\n",
    "    if y.shape[0] != n or y.shape[1] != 1:\n",
    "        raise ValueError(\"y must be a column vector of length n.\")\n",
    "    \n",
    "    # Step 2: Compute matrix components\n",
    "    XtX = np.dot(X.T, X)\n",
    "    XtZ = np.dot(X.T, Z)\n",
    "    ZtX = XtZ.T  # Since XtZ is (p x q), ZtX is (q x p)\n",
    "    ZtZ = np.dot(Z.T, Z)\n",
    "    \n",
    "    # Step 3: Compute inverse of G with regularization\n",
    "    try:\n",
    "        # Compute condition number to assess singularity\n",
    "        cond_G = np.linalg.cond(G)\n",
    "        if cond_G > 1e10:  # High condition number indicates ill-conditioning\n",
    "            print(\"Warning: G matrix is ill-conditioned. Adding regularization.\")\n",
    "            G_reg = G + np.eye(G.shape[0]) * reg_factor\n",
    "            G_inv = np.linalg.inv(G_reg)\n",
    "        else:\n",
    "            G_inv = np.linalg.inv(G)\n",
    "    except np.linalg.LinAlgError:\n",
    "        print(\"G matrix is singular. Adding regularization to proceed.\")\n",
    "        G_reg = G + np.eye(G.shape[0]) * reg_factor\n",
    "        G_inv = np.linalg.inv(G_reg)\n",
    "    \n",
    "    # Step 4: Construct matrix A with regularization\n",
    "    lambda_ = sigma_e / sigma_g\n",
    "    A_upper = np.hstack((XtX, XtZ))\n",
    "    A_lower = np.hstack((ZtX, ZtZ + lambda_ * G_inv))\n",
    "    A = np.vstack((A_upper, A_lower))\n",
    "    \n",
    "    # Add regularization to A for numerical stability\n",
    "    A_reg = A + np.eye(A.shape[0]) * reg_factor\n",
    "    \n",
    "    # Step 5: Construct vector b\n",
    "    Xty = np.dot(X.T, y)\n",
    "    Zty = np.dot(Z.T, y)\n",
    "    b = np.vstack((Xty, Zty))\n",
    "    \n",
    "    # Step 6: Solve the equation system A_reg * x = b\n",
    "    try:\n",
    "        x = np.linalg.solve(A_reg, b)\n",
    "    except np.linalg.LinAlgError as e:\n",
    "        print(f\"Error solving the system: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # Step 7: Split beta and g\n",
    "    fixed_effects = p\n",
    "    beta = x[:fixed_effects]\n",
    "    g = x[fixed_effects:]\n",
    "\n",
    "    # Calculate PEV: Predicted Error Variance\n",
    "    A_inv = np.linalg.inv(A_reg)\n",
    "    PEV, acc = calculate_pev_and_accuracy(sigma_g, sigma_e, A_inv, n)\n",
    "    \n",
    "    return beta, g, PEV, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Create example data with specified dimensions\n",
    "    np.random.seed(2025)\n",
    "    n_samples = 1000  # Number of samples/observations\n",
    "    n_markers = 10  # Number of markers\n",
    "    \n",
    "    # X matrix: n samples, 5 fixed effects\n",
    "    X = np.ones((n_samples, 5))\n",
    "    # add random values to X with normal distribution mean=0, std=0.5\n",
    "    X[:, 1:] = np.random.normal(0, 0.5, size=(n_samples, 4))\n",
    "    \n",
    "    # Z matrix: samples x markers (random 0, 1, 2 genotypes)\n",
    "    M = np.random.randint(0, 3, size=(n_samples, n_markers))\n",
    "    Z = np.eye(n_samples)  # Identity matrix for simplicity\n",
    "    \n",
    "    # Calculate genomic relationship matrix G\n",
    "    G = calculate_G_matrix(M, method='vanraden1')\n",
    "    print(\"G matrix:\")\n",
    "    print(G)\n",
    "    if not np.all(np.linalg.eigvals(G) > 0):\n",
    "        print(\"Warning: G matrix is not positive definite. Adding regularization.\")\n",
    "        G = G + np.eye(G.shape[0]) * 1e-4\n",
    "    \n",
    "    # Generate random phenotypes\n",
    "    y = np.random.normal(0, 1, size=(n_samples, 1))\n",
    "\n",
    "    # Estimate variance components\n",
    "    sigma_g, sigma_e = estimate_variance_components(y, X, Z, G)\n",
    "    print(f\"Genomic variance (sigma_g^2): {sigma_g:.6f}\")\n",
    "    print(f\"Error variance (sigma_e^2): {sigma_e}\")\n",
    "    \n",
    "    # Solve GBLUP equation system\n",
    "    beta, g, PEV, acc = solve_gblup(y, X, Z, G, sigma_g, sigma_e)\n",
    "    print(\"\\nEstimated fixed effects beta:\")\n",
    "    print(beta)\n",
    "    print(\"\\nEstimated genomic breeding values g:\")\n",
    "    print(g)\n",
    "    print(\"\\nPrediction Error Variance (PEV):\")\n",
    "    print(PEV)\n",
    "    print(\"\\nAccuracy:\")\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(np.linalg.eigvals(G + np.eye(G.shape[0]) * 1e-05) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "def analyze_genomic_correlations(y: np.ndarray, g: np.ndarray, X=None, beta=None, plot=True):\n",
    "    \"\"\"\n",
    "    Calculate correlations between genomic breeding values and phenotypes,\n",
    "    with optional analysis of fixed effects contribution.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    y : np.ndarray\n",
    "        Observed phenotypes (n x 1)\n",
    "    g : np.ndarray\n",
    "        Estimated genomic breeding values (n x 1)\n",
    "    X : np.ndarray, optional\n",
    "        Design matrix for fixed effects (n x p)\n",
    "    beta : np.ndarray, optional\n",
    "        Fixed effects estimates (p x 1)\n",
    "    plot : bool, optional\n",
    "        Whether to create correlation plots (default: True)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary of correlation statistics\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # Calculate direct correlation between g and y\n",
    "    pearson_corr, pearson_p = pearsonr(g.flatten(), y.flatten())\n",
    "    spearman_corr, spearman_p = spearmanr(g.flatten(), y.flatten())\n",
    "    \n",
    "    results['g_y_pearson'] = (pearson_corr, pearson_p)\n",
    "    results['g_y_spearman'] = (spearman_corr, spearman_p)\n",
    "    \n",
    "    # Calculate fixed effects contribution if provided\n",
    "    if X is not None and beta is not None:\n",
    "        fixed_effects = np.dot(X, beta)\n",
    "        results['fixed_var'] = np.var(fixed_effects)\n",
    "        results['random_var'] = np.var(g)\n",
    "        results['total_var'] = np.var(y)\n",
    "        \n",
    "        # Calculate proportion of variance explained\n",
    "        results['fixed_proportion'] = results['fixed_var'] / results['total_var']\n",
    "        results['random_proportion'] = results['random_var'] / results['total_var']\n",
    "    \n",
    "    # Create plots if requested\n",
    "    if plot:\n",
    "        # Plot 1: g vs y\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.scatter(g, y, alpha=0.5, edgecolor='k')\n",
    "        plt.xlabel('Genomic Breeding Values (g)')\n",
    "        plt.ylabel('Phenotypes (y)')\n",
    "        plt.title(f'Correlation: {pearson_corr:.3f} (p={pearson_p:.3e})')\n",
    "        plt.grid(alpha=0.3)\n",
    "        \n",
    "        # Add regression line\n",
    "        m, b = np.polyfit(g.flatten(), y.flatten(), 1)\n",
    "        x_line = np.linspace(min(g), max(g), 100)\n",
    "        y_line = m * x_line + b\n",
    "        plt.plot(x_line, y_line, 'r--', label=\"regression line\")\n",
    "\n",
    "        # Add y = x line\n",
    "        # plt.plot([min(y), max(y)], [min(y), max(y)], 'k--', alpha=1, label=\"y = x line\")\n",
    "        plt.legend()\n",
    "        \n",
    "        # Plot 2: Histogram of genomic values\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.hist(g, bins=50, alpha=0.7, edgecolor='k', density=True)\n",
    "        plt.xlabel('Genomic Breeding Values (g)')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title(f'Distribution of Genomic Values\\nMean={np.mean(g):.3f}, SD={np.std(g):.3f}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    return results\n",
    "\n",
    "# Run the analysis\n",
    "corr_results = analyze_genomic_correlations(y, g, X, beta)\n",
    "\n",
    "# Print summary\n",
    "print(f\"Correlation between genomic breeding values and phenotypes:\")\n",
    "print(f\"Pearson:  r = {corr_results['g_y_pearson'][0]:.4f}, p = {corr_results['g_y_pearson'][1]:.4e}\")\n",
    "print(f\"Spearman: œÅ = {corr_results['g_y_spearman'][0]:.4f}, p = {corr_results['g_y_spearman'][1]:.4e}\")\n",
    "\n",
    "if 'fixed_proportion' in corr_results:\n",
    "    print(f\"\\nVariance proportions:\")\n",
    "    print(f\"Fixed effects: {corr_results['fixed_proportion']*100:.2f}%\")\n",
    "    print(f\"Genomic values: {corr_results['random_proportion']*100:.2f}%\")\n",
    "    print(f\"Unexplained: {(1-corr_results['fixed_proportion']-corr_results['random_proportion'])*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vgp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
